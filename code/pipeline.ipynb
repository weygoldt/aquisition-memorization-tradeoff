{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from modules.functions import bound_logistic\n",
    "from modules.plotstyle import PlotStyle\n",
    "import matplotlib.colors as mcolors\n",
    "import plottools.colors as clrs\n",
    "import cmocean.cm as cmo\n",
    "import seaborn as sns\n",
    "%matplotlib qt\n",
    "\n",
    "# init standardized plotstyle\n",
    "ps = PlotStyle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4AFC Analysis\n",
    "\n",
    "- Fit logistic functions to detection proportions of all subjects to estimate their individual detection threshold\n",
    "- Compare detection thresholds across the two levels of stimulus duration\n",
    "\n",
    "First, load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound_logistic ran in: 1.9073486328125e-06 sec\n"
     ]
    }
   ],
   "source": [
    "def find_nearest(array, value):\n",
    "    \"\"\"Like numpy-where but flexible\"\"\"\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx] \n",
    "\n",
    "def find_nearest_idx(array, value):\n",
    "    \"\"\"Like numpy-where but flexible\"\"\"\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "logistic = bound_logistic(0.25, 1) # logistic bound between chance lvl and 1\n",
    "\n",
    "data = pd.read_csv('../data_processed/4afc_all.csv') # load 4afc data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset, we can exclude data that may conflict with our analysis.\n",
    "For the first criterion, we exclude subjects where **more than 50% of the performances where worse that chance level**. These subjects could have selected the wrong answer on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs some attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate across all subjects, fit the logistic function for both stimulus conditions and extract the respective detection thresholds on the fitted function. \n",
    "\n",
    "**Thresholds that are above or beyond our stimulus boundaries will be used as indicators to exclude the subject from the subsequent analysis.**\n",
    "\n",
    "They gray lines and datapoints represent these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [] # append names here\n",
    "conds =  [] # append condition here\n",
    "fits = [] # append fitted curve here\n",
    "threshs = [] # append thresh from logistic fit here\n",
    "exclude = [] # append exclude index here\n",
    "\n",
    "for it, condition in enumerate(np.unique(data.cat)):\n",
    "\n",
    "    # define colors for each subject\n",
    "    color = iter(cm.rainbow(np.linspace(0, 1, 8)))\n",
    "\n",
    "    # compute thresholds and exclude where threshold is out of range\n",
    "    for i, name in enumerate(np.unique(data.subj)):\n",
    "\n",
    "        # get data for this subject\n",
    "        x = np.asarray(data.what[(data.cat == condition)&(data.subj == name)], dtype=float)\n",
    "        y = np.asarray(data.prop[(data.cat == condition)&(data.subj == name)], dtype=float)\n",
    "\n",
    "        # fit the logistic function to get a psychometric curve\n",
    "        popt, pcov = curve_fit(logistic, x, y, method='trf', maxfev=100000)\n",
    "\n",
    "        # make the model curve\n",
    "        x_fit = np.arange(0, 0.14, 0.0001)\n",
    "        y_fit = logistic(x_fit, *popt)\n",
    "\n",
    "        # extract threshold (where detection is half of non-chance range)\n",
    "        thresh = np.round(x_fit[y_fit == find_nearest(y_fit,0.625)][0], 3)\n",
    "        thresh_y = y_fit[y_fit == find_nearest(y_fit,0.625)][0]\n",
    "\n",
    "        if (thresh>0.1) or (thresh<0.01667):\n",
    "            exclude.extend([1])\n",
    "            names.append(name)\n",
    "            fits.append(y_fit)\n",
    "            conds.append(condition)\n",
    "            threshs.append(thresh)\n",
    "        else:\n",
    "            exclude.extend([0])\n",
    "            names.append(name)\n",
    "            fits.append(y_fit)\n",
    "            conds.append(condition)\n",
    "            threshs.append(thresh)\n",
    "\n",
    "# make a dataframe from the collected data\n",
    "exclude = np.asanyarray(exclude, dtype=bool)\n",
    "names = np.asarray(names, dtype=str)\n",
    "fits = np.asarray(fits, dtype=float)\n",
    "conds = np.asarray(conds, dtype=str)\n",
    "threshs = np.asarray(threshs, dtype=float)\n",
    "\n",
    "# make exclude for both levels\n",
    "for name in np.unique(names):\n",
    "    if 1 in exclude[names==name]:\n",
    "        exclude[names==name] = 1\n",
    "\n",
    "dthresh = pd.DataFrame(np.asarray([names, exclude, conds, threshs], dtype=object).T, columns=('name', 'exclude', 'cond', 'thresh'))\n",
    "dthresh = dthresh.astype({\"name\": str, \"exclude\": bool, \"cond\": str, \"thresh\": float})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the detection threshold for each person, we also want to know whether the detection thresholds differ between the two spatial frequencies. For low spatial frequencies it should be easier to detect the orientation of the grating faster.\n",
    "\n",
    "Lets first plot a boxplot of the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20632/3226321771.py:4: MatplotlibDeprecationWarning: The join function was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n",
      "  ax[0].get_shared_x_axes().join(ax[0], ax[1])\n",
      "/tmp/ipykernel_20632/3226321771.py:5: MatplotlibDeprecationWarning: The join function was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n",
      "  ax[0].get_shared_y_axes().join(ax[0], ax[1])\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fca527a2aa0>"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since where already fitting, lets also plot this\n",
    "fig, ax = plt.subplots(1,3, figsize=(25*ps.cm,10*ps.cm), constrained_layout=True)\n",
    "\n",
    "ax[0].get_shared_x_axes().join(ax[0], ax[1])\n",
    "ax[0].get_shared_y_axes().join(ax[0], ax[1])\n",
    "\n",
    "x = x_fit\n",
    "x_stim = x_fit[(x_fit<0.1)&(x_fit>0.01667)]\n",
    "\n",
    "for i, cond in enumerate(np.unique(dthresh.cond)):\n",
    "\n",
    "    # set colors \n",
    "    color = iter(clrs.colors_tableau)\n",
    "    color = iter(cmo.haline(np.linspace(0, 1, 6)))\n",
    "    \n",
    "    for index in dthresh.index[dthresh.cond == cond]:\n",
    "\n",
    "        fit = fits[index]\n",
    "        fit_stim = fits[index][(x_fit<0.1)&(x_fit>0.01667)]\n",
    "        \n",
    "        if dthresh.exclude[index] == True:\n",
    "            zorder = -10\n",
    "            ax[i].plot(x, fit, c='lightgray', lw=2.5, zorder=zorder)\n",
    "            ax[i].plot([dthresh.thresh[index], dthresh.thresh[index]], [0.25, find_nearest(fit, 0.625)], lw=1, c='lightgray', ls='dashed', zorder=zorder)\n",
    "            ax[i].plot([dthresh.thresh[index]], [find_nearest(fit, 0.625)], marker='o', c='lightgray', zorder=zorder, markersize=7.5)\n",
    "            \n",
    "        else: \n",
    "            c = next(color)\n",
    "            ax[i].plot(x, fit, lw=2.5, c=c, ls='dashed', zorder=-1)\n",
    "            ax[i].plot(x_stim, fit_stim, lw=2.5, c=c, zorder=1)\n",
    "            ax[i].plot([dthresh.thresh[index], dthresh.thresh[index]], [0.25, find_nearest(fit, 0.625)], lw=1, c=c)\n",
    "            ax[i].plot([dthresh.thresh[index]], [find_nearest(fit, 0.625)], marker='o', c=c, markersize=7.5)\n",
    "\n",
    "ax[1].text(0, 0.9, '2 cpd')\n",
    "ax[0].text(0, 0.9, '8 cpd')\n",
    "ax[1].set_ylim(0.25, 1)\n",
    "ax[0].set_ylim(0.25, 1)\n",
    "ax[0].set_ylabel('prop. correct')\n",
    "ax[0].set_xlabel('stim. dur. [s]')\n",
    "ax[1].set_xlabel('stim. dur. [s]')\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the invalid datasets\n",
    "dthresh_valid = dthresh[dthresh[\"exclude\"] == False]\n",
    "\n",
    "sbp = sns.pointplot(x = 'cond', y = 'thresh', hue='name', data = dthresh_valid, palette='viridis', ax=ax[2])\n",
    "ax[2].set_xlabel('stimulus')\n",
    "ax[2].set_ylabel('det. thresh')\n",
    "\n",
    "ax[2].set_xticklabels(['8 cpd', '2 cpd'])\n",
    "plt.legend([],[], frameon=False)\n",
    "\n",
    "plt.savefig('4afc_psychofit.svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('vwmenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8255c074632b1c81c2691853723a10c160401814b29754ce4c04cbcbe3a4c4db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
