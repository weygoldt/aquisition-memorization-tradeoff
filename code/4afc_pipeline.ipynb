{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from modules.functions import bound_logistic\n",
    "from modules.plotstyle import PlotStyle\n",
    "import matplotlib.colors as mcolors\n",
    "import plottools.colors as clrs\n",
    "import cmocean.cm as cmo\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "import cmocean\n",
    "from modules.functions import figsave\n",
    "%matplotlib qt\n",
    "\n",
    "# init standardized plotstyle\n",
    "ps = PlotStyle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4AFC Analysis\n",
    "\n",
    "- Fit logistic functions to detection proportions of all subjects to estimate their individual detection threshold\n",
    "- Compare detection thresholds across the two levels of stimulus duration\n",
    "\n",
    "First, load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound_logistic ran in: 3.337860107421875e-06 sec\n"
     ]
    }
   ],
   "source": [
    "def find_nearest(array, value):\n",
    "    \"\"\"Like numpy-where but flexible\"\"\"\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx] \n",
    "\n",
    "def find_nearest_idx(array, value):\n",
    "    \"\"\"Like numpy-where but flexible\"\"\"\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "logistic = bound_logistic(0.25, 1) # logistic bound between chance lvl and 1\n",
    "\n",
    "data = pd.read_csv('../data_processed/4afc_all.csv') # load 4afc data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset, we can exclude data that may conflict with our analysis.\n",
    "For the first criterion, we exclude subjects where **more than 50% of the performances where worse that chance level**. These subjects could have selected the wrong answer on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs some attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate across all subjects, fit the logistic function for both stimulus conditions and extract the respective detection thresholds on the fitted function. \n",
    "\n",
    "**Thresholds that are above or beyond our stimulus boundaries will be used as indicators to exclude the subject from the subsequent analysis.**\n",
    "\n",
    "They gray lines and datapoints represent these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [] # append names here\n",
    "conds =  [] # append condition here\n",
    "fits = [] # append fitted curve here\n",
    "threshs = [] # append thresh from logistic fit here\n",
    "exclude = [] # append exclude index here\n",
    "\n",
    "for it, condition in enumerate(np.unique(data.cat)):\n",
    "\n",
    "    # define colors for each subject\n",
    "    color = iter(cm.rainbow(np.linspace(0, 1, 8)))\n",
    "\n",
    "    # compute thresholds and exclude where threshold is out of range\n",
    "    for i, name in enumerate(np.unique(data.subj)):\n",
    "\n",
    "        # get data for this subject\n",
    "        x = np.asarray(data.what[(data.cat == condition)&(data.subj == name)], dtype=float)\n",
    "        y = np.asarray(data.prop[(data.cat == condition)&(data.subj == name)], dtype=float)\n",
    "\n",
    "        # fit the logistic function to get a psychometric curve\n",
    "        popt, pcov = curve_fit(logistic, x, y, method='trf', maxfev=100000)\n",
    "\n",
    "        # make the model curve\n",
    "        x_fit = np.arange(0, 0.14, 0.0001)\n",
    "        y_fit = logistic(x_fit, *popt)\n",
    "\n",
    "        # extract threshold (where detection is half of non-chance range)\n",
    "        thresh = np.round(x_fit[y_fit == find_nearest(y_fit,0.625)][0], 3)\n",
    "        thresh_y = y_fit[y_fit == find_nearest(y_fit,0.625)][0]\n",
    "\n",
    "        if (thresh>0.1) or (thresh<0.01667):\n",
    "            exclude.extend([1])\n",
    "            names.append(name)\n",
    "            fits.append(y_fit)\n",
    "            conds.append(condition)\n",
    "            threshs.append(thresh)\n",
    "        else:\n",
    "            exclude.extend([0])\n",
    "            names.append(name)\n",
    "            fits.append(y_fit)\n",
    "            conds.append(condition)\n",
    "            threshs.append(thresh)\n",
    "\n",
    "# make a dataframe from the collected data\n",
    "exclude = np.asanyarray(exclude, dtype=bool)\n",
    "names = np.asarray(names, dtype=str)\n",
    "fits = np.asarray(fits, dtype=float)\n",
    "conds = np.asarray(conds, dtype=str)\n",
    "threshs = np.asarray(threshs, dtype=float)\n",
    "\n",
    "# make exclude for both levels\n",
    "for name in np.unique(names):\n",
    "    if 1 in exclude[names==name]:\n",
    "        exclude[names==name] = 1\n",
    "\n",
    "dthresh = pd.DataFrame(np.asarray([names, exclude, conds, threshs], dtype=object).T, columns=('name', 'exclude', 'cond', 'thresh'))\n",
    "dthresh = dthresh.astype({\"name\": str, \"exclude\": bool, \"cond\": str, \"thresh\": float})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we build now contains each subjects detection threshold for both categories and whether we want to include or exclude the subject from subsequent analyses. Now we can plot the fits, thresholds and wether the threshold changes with spatial frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79597/1547440163.py:5: MatplotlibDeprecationWarning: The join function was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n",
      "  ax[0].get_shared_x_axes().join(ax[0], ax[1])\n",
      "/tmp/ipykernel_79597/1547440163.py:6: MatplotlibDeprecationWarning: The join function was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n",
      "  ax[0].get_shared_y_axes().join(ax[0], ax[1])\n"
     ]
    }
   ],
   "source": [
    "# since where already fitting, lets also plot this\n",
    "fig, ax = plt.subplots(1,3, figsize=(25*ps.cm,10*ps.cm), constrained_layout=True)\n",
    "\n",
    "# make axis shared\n",
    "ax[0].get_shared_x_axes().join(ax[0], ax[1])\n",
    "ax[0].get_shared_y_axes().join(ax[0], ax[1])\n",
    "\n",
    "x = x_fit\n",
    "x_stim = x_fit[(x_fit<0.1)&(x_fit>0.01667)]\n",
    "newcmap = cmocean.tools.crop_by_percent(cmo.ice, 20, which='max', N=None)\n",
    "\n",
    "\n",
    "for i, cond in enumerate(np.unique(dthresh.cond)):\n",
    "\n",
    "    # set colors \n",
    "    color = iter(clrs.colors_tableau)\n",
    "    color = iter(cm.viridis(np.linspace(0, 1, 6)))\n",
    "    color = newcmap(np.linspace(0, 1, 6))\n",
    "    ic = 0\n",
    "    for index in dthresh.index[dthresh.cond == cond]:\n",
    "\n",
    "        fit = fits[index]\n",
    "        fit_stim = fits[index][(x_fit<0.1)&(x_fit>0.01667)]\n",
    "        \n",
    "        if dthresh.exclude[index] == True:\n",
    "            zorder = -10\n",
    "            ax[i].plot(x, fit, c='lightgray', lw=2.5, zorder=zorder)\n",
    "            ax[i].plot([dthresh.thresh[index], dthresh.thresh[index]], [0.25, find_nearest(fit, 0.625)], lw=1, c='lightgray', ls='dashed', zorder=zorder)\n",
    "            ax[i].plot([dthresh.thresh[index]], [find_nearest(fit, 0.625)], marker='o', c='lightgray', zorder=zorder, markersize=7.5)\n",
    "            \n",
    "        else: \n",
    "            #c = next(color)\n",
    "            c = color[ic]\n",
    "            ax[i].plot(x, fit, lw=2.5, c=c, ls='dashed', zorder=-1)\n",
    "            ax[i].plot(x_stim, fit_stim, lw=2.5, c=c, zorder=1)\n",
    "            ax[i].plot([dthresh.thresh[index], dthresh.thresh[index]], [0.25, find_nearest(fit, 0.625)], lw=1, c=c)\n",
    "            ax[i].plot([dthresh.thresh[index]], [find_nearest(fit, 0.625)], marker='o', c=c, markersize=7.5)\n",
    "            ic += 1\n",
    "\n",
    "\n",
    "ax[1].text(0, 0.9, '2 cpd')\n",
    "ax[0].text(0, 0.9, '8 cpd')\n",
    "ax[1].set_ylim(0.25, 1)\n",
    "ax[0].set_ylim(0.25, 1)\n",
    "ax[0].set_ylabel('prop. correct')\n",
    "ax[0].set_xlabel('stim. dur. [s]')\n",
    "ax[1].set_xlabel('stim. dur. [s]')\n",
    "\n",
    "# remove the invalid datasets\n",
    "dthresh_valid = dthresh[dthresh[\"exclude\"] == False]\n",
    "\n",
    "# plot pointplot\n",
    "sbp = sns.pointplot(x = 'cond', y = 'thresh', hue='name', data = dthresh_valid, palette=color, ax=ax[2])\n",
    "ax[2].set_xlabel('stimulus')\n",
    "ax[2].set_ylabel('det. thresh')\n",
    "\n",
    "# set ticklabels, remove legends\n",
    "ax[2].set_xticklabels(['8 cpd', '2 cpd'])\n",
    "plt.legend([],[], frameon=False)\n",
    "\n",
    "# save\n",
    "figsave('4afc_psychofit')\n",
    "plt.show()\n",
    "\n",
    "dthresh_valid.to_csv('../data_processed/4afc_thresh.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the detection threshold for each person, as well as the change of the detection threshold between the stimuli of two different spatial frequencies. It appears as if the threshold decreases with increasing spatial frequency. This would be expected, because the larger spatial frequency is easier to perceive. Lets test this using a wilcoxon signed rank test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  exclude  cond  thresh\n",
      "0    Lorenz    False  high   0.070\n",
      "1   Patrick    False  high   0.078\n",
      "5       VP5    False  high   0.073\n",
      "7       VP7    False  high   0.049\n",
      "8       eva    False  high   0.044\n",
      "9       vp4    False  high   0.074\n",
      "10   Lorenz    False   low   0.057\n",
      "11  Patrick    False   low   0.088\n",
      "15      VP5    False   low   0.051\n",
      "17      VP7    False   low   0.033\n",
      "18      eva    False   low   0.034\n",
      "19      vp4    False   low   0.058\n",
      "[[0.01531167 0.02252059 0.07272874 1.        ]\n",
      " [0.15865747 0.1522885  0.30891298 1.        ]\n",
      " [0.24407846 0.28286389 0.56934544 1.        ]\n",
      " [0.25218623 0.45762206 0.71025565 1.        ]\n",
      " [0.35674518 0.62931345 0.77144009 1.        ]\n",
      " [0.544354   0.79220975 0.83631331 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(dthresh_valid)\n",
    "print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WilcoxonResult(statistic=1.5, pvalue=0.0625)\n"
     ]
    }
   ],
   "source": [
    "# do a wilcoxon signed rank test\n",
    "low = dthresh_valid.thresh[dthresh_valid[\"cond\"] == 'low']\n",
    "high = dthresh_valid.thresh[dthresh_valid[\"cond\"] == 'high']\n",
    "\n",
    "# print test result\n",
    "stat = wilcoxon(low, high)\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the p-value is not significant, which was to be expected from a sample size this low and a trend this inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVS task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vwmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8255c074632b1c81c2691853723a10c160401814b29754ce4c04cbcbe3a4c4db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
